{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Random Forest Implementation From Scratch in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libaries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This class is used to create the decision tree. We have covered this algorithm in Decision Tree tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "\n",
    "\t# Formula - -pi * log(pi)\n",
    "\t# pi = number1/(number1 + number2)\n",
    "\tdef calculate_entropy(self,num,denominator):\n",
    "\t     \n",
    "\t     pi = num/denominator\n",
    "\t     if pi == 0:\n",
    "\t     \t# To avoid divided by zero when calculating np.log2\n",
    "\t     \treturn 0\n",
    "\t     else:\t\n",
    "\t     \treturn -pi*np.log2(pi)\n",
    "\n",
    "\t# Calculate E(Target) - Entropy of Target\n",
    "\tdef calculate_target_entropy(self,vector):\n",
    "\t\tentropy = 0\n",
    "\t\tvalues = vector.value_counts()\n",
    "\t\ttotal = len(vector)\n",
    "\t\tfor value in values:\n",
    "\t\t\tentropy += self.calculate_entropy(value,total)\n",
    "\t\treturn entropy\t\n",
    "\n",
    "\t# Calculate E(Target | Attribute) - Entropy of Features\n",
    "\tdef calculate_attribute_entropy(self,dataset,attribute,target):\n",
    "\t\ttargets = dataset[target].unique()\n",
    "\t\tattribute_vector = dataset[attribute]\n",
    "\t\t\n",
    "\t\ttotal_samples = len(attribute_vector)\n",
    "\t\tproperties = attribute_vector.unique()\n",
    "\t\tentropy = 0\n",
    "\t\tfor prop in properties:\n",
    "\t\t\tprop_entropy = 0\n",
    "\t\t\tdenominator = len(dataset[attribute][ dataset[attribute] == prop ])\n",
    "\t\t\tfor target_class in targets:\n",
    "\t\t\t\tnumber = len(dataset[attribute][ dataset[attribute] == prop ][dataset[target] == target_class ])\n",
    "\t\t\t\tprop_entropy += self.calculate_entropy(number,denominator)\n",
    "\n",
    "\t\t\tp_attribute = denominator/total_samples\n",
    "\t\t\tentropy += p_attribute*prop_entropy\n",
    "\t\treturn entropy\n",
    "\n",
    "\t# Calculate Information Gain of Features\t\n",
    "\t# Formula = E(Target) - E(Target| Attribute)\n",
    "\tdef calculate_information_gain(self,dataset,attribute,target):\n",
    "\t\ttarget_entropy = self.calculate_target_entropy(dataset[target])\n",
    "\t\tattribute_entropy = self.calculate_attribute_entropy(dataset,attribute,target)\n",
    "\t\treturn target_entropy - attribute_entropy\n",
    "\n",
    "\n",
    "\t# Find out decision node by calulating max Information Gain\n",
    "\tdef winner_attribute(self,df):\n",
    "\t\t\n",
    "\t\tinformation_gain = []\n",
    "\t\ttarget = df.keys()[-1]\n",
    "\t\tfeatures =  df.keys()[:-1] # Exclude the last one.\n",
    "\t\t\n",
    "\t\tfor feature in features: \n",
    "\t\t\tinformation_gain.append(self.calculate_information_gain(df,feature,target))\n",
    "\t\t\n",
    "\t\tmaximum_ig_index = np.argmax(information_gain)\n",
    "\t\twinner_feature = features[maximum_ig_index]\n",
    "\t\treturn winner_feature\n",
    "\n",
    "\t# Split the dataset on decision node\t\n",
    "\tdef split_dataset(self,df,node,value):\n",
    "\t\treturn df[df[node] == value].reset_index(drop=True)\n",
    "\n",
    "\t# Build Decision Tree\n",
    "\tdef build_tree(self,df,tree=None):\n",
    "\t\ttarget_class = df.keys()[-1]\n",
    "\t\tnode = self.winner_attribute(df)\n",
    "\t\tnode_values= df[node].unique()\n",
    "\t\tif tree is None:\n",
    "\t\t\ttree= {}\n",
    "\t\t\ttree[node] = {}\n",
    "\t\tfor value in node_values:\n",
    "\t\t\tsubtable = self.split_dataset(df,node,value)\n",
    "\t\t\tsubset_target_class = subtable[target_class].unique()\n",
    "\t\t\tif len(subset_target_class) == 1:\n",
    "\t\t\t\ttree[node][value] = subset_target_class[0]\n",
    "\t\t\telse:\n",
    "\t\t\t\ttree[node][value] = self.build_tree(subtable)\n",
    "\n",
    "\t\treturn tree\n",
    "\n",
    "\t# Start training process. Ultimate goal is to make a decision tree.\n",
    "\tdef fit(self,df):\n",
    "\t\tself.tree = self.build_tree(df)\t\n",
    "\n",
    "\n",
    "\t# Traverse through decision tree.\n",
    "\tdef traverse_tree(self,guess,tree):\n",
    "\n",
    "\t   prediction = ''\n",
    "\t   for node in tree.keys():\n",
    "\t   \tvalue = guess[node]\n",
    "\t   \ttree = tree[node][value]\n",
    "\t   \n",
    "\t   \tif type(tree) is dict:\n",
    "\t   \t\tprediction = self.traverse_tree(guess,tree)\n",
    "\t   \telse:\n",
    "\t   \t\tprediction = tree\n",
    "\t   \t\tbreak\n",
    "\n",
    "\t   return prediction\n",
    "\n",
    "\n",
    "\t# Predict the class using Input values\n",
    "\tdef predict(self,guess):\n",
    "\n",
    "\t   prediction = ''\n",
    "\t   tree = self.tree\n",
    "\t   prediction = self.traverse_tree(guess,tree)\n",
    "\t   return prediction\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A class to Implement Random Forest Clasifier from scratch\\n\\nThis class divides a dataset into small dataset and create a decision tree on each subset.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''A class to Implement Random Forest Clasifier from scratch\n",
    "\n",
    "This class divides a dataset into small dataset and create a decision tree on each subset.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "\n",
    "\tdef __init__(self,n_trees,n_features,sample_sz,depth=10,min_leaf=5):\n",
    "\t\tnp.random.seed(12)\n",
    "\n",
    "\t\tself.n_features = n_features\n",
    "\t\tself.n_trees = n_trees\n",
    "\t\tself.sample_sz, self.depth, self.min_leaf = sample_sz,depth,min_leaf\n",
    "\t\t\n",
    "\n",
    "\tdef fit(self, feature, target):\n",
    "\t\t\n",
    "\t\t# Decide number of fetures in each subset\n",
    "\t\tif self.n_features == 'sqrt':\n",
    "\t\t\tself.n_features = int( np.sqrt(features.shape[1]))\n",
    "\t\telif self.n_features == 'log2':\n",
    "\t\t\tself.n_features = int(np.log2(features.shape[1]))\n",
    "\t\n",
    "\t\tself.x = features\n",
    "\t\tself.y = target\n",
    "\t\tself.trees = [self.create_tree() for i in range(self.n_trees)]\t\n",
    "\n",
    "\tdef create_tree(self):\n",
    "\t\t# Divide databse into small dataset\n",
    "\t\tidxs = np.random.permutation(len(self.y))[:self.sample_sz]\n",
    "\t\tf_idxs = np.random.permutation(self.x.shape[1])[:self.n_features]\n",
    "\t\ty = self.y[idxs].reshape(-1,1)\n",
    "\t\tx = self.x[idxs]\n",
    "\t\tdataset = np.concatenate((x,y),axis=1)\n",
    "\t\t\n",
    "\t\t# Convert dataset into dataframe\n",
    "\t\tdataframe = pd.DataFrame(dataset)\n",
    "\t\t\n",
    "\t\t# Use DecisionTree class to create a decision for this small dataset\n",
    "\t\tmodel = DecisionTree()\n",
    "\t\tmodel.fit(dataframe)\n",
    "\t\treturn model\n",
    "\n",
    "\tdef predict(self,x):\n",
    "\t\tprediction = []\n",
    "\t\t# Predict possible class using number of decision tree created on small subset of dataset.\n",
    "\t\tfor dt in self.trees:\n",
    "\t\t\tprediction.append(dt.predict(x))\n",
    "\n",
    "\t\treturn prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data - (weight (kg), Height (cm), gender)\n",
    "dataset = np.array([\n",
    "\t\t   ['Salty','Hot','Soft','No'],\n",
    "\t\t   ['Spicy','Hot','Soft','No'],\n",
    "\t\t   ['Spicy','Hot','Hard','Yes'],\n",
    "\t\t   ['Spicy','Cold','Hard','No'],\n",
    "\t\t   ['Spicy','Hot','Hard','Yes'],\n",
    "\t\t   ['Sweet','Cold','Soft','Yes'],\n",
    "\t\t   ['Salty','Cold','Soft','No'],\n",
    "\t\t   ['Sweet','Hot','Soft','Yes'],\n",
    "\t\t   ['Spicy','Cold','Soft','Yes'],\n",
    "\t\t   ['Salty','Hot','Hard','Yes'],\n",
    "\t\t   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featues & Target columns\n",
    "features= dataset[:,0:-1]\n",
    "target= dataset[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem - Should I eat if taste is salty, temperature is hot and texture is hard?\n",
    "data = {'Taste':'Spicy','Temperature':'Cold','Texture':'Soft'}\n",
    "guess = pd.Series(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Random Forest Model\n",
    "model = RandomForest(5,'log2',6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "model.fit(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class \n",
    "prediction = model.predict(guess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should I eat if taste is Spicy, temperature is Cold and texture is Soft ? - Yes\n"
     ]
    }
   ],
   "source": [
    "#output\n",
    "most_voted = max(set(prediction), key = prediction.count)\n",
    "\n",
    "print(\"Should I eat if taste is %s, temperature is %s and texture is %s ? - %s\" % (data['Taste'],data['Temperature'],data['Texture'],most_voted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
